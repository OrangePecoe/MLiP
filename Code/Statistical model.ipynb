{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom pandas.plotting import autocorrelation_plot\nfrom statsmodels.graphics.tsaplots import plot_pacf\n\nfrom statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.discrete.discrete_model import NegativeBinomialP,NegativeBinomial,Poisson\nfrom statsmodels.graphics.boxplots import violinplot\nfrom scipy.stats import boxcox\nfrom scipy.special import inv_boxcox\nimport pywt\nfrom statsmodels.robust import mad\nfrom statsmodels.discrete.count_model import ZeroInflatedNegativeBinomialP\nfrom statsmodels.discrete.count_model import ZeroInflatedPoisson\nfrom statsmodels.tsa.api import VAR\nfrom statsmodels.tsa.api import VARMAX\nfrom statsmodels.tsa.statespace.dynamic_factor import DynamicFactor\nfrom statsmodels.tsa.api import Holt\nfrom statsmodels.tsa.regime_switching.markov_regression import MarkovRegression\n\nimport seaborn as sns\nfrom scipy.stats import nbinom\nfrom statistics import mean,stdev\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom scipy import stats  \n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nimport time\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# What needs to be forecasted; daily sales for the next 28 days per item per store.\nsales_data = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv\")\nprice_data = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sell_prices.csv\")\ncalender_data = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/calendar.csv\")\nsubmission_data = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = calender_data[{'wday','month','year','snap_CA','snap_TX','snap_WI','event_type_1','event_type_2'}]\nfeatures = features[0:len(features)]\nfeatures = features.fillna(value=0)\nfeatures = features.replace(\"Religious\",1)\nfeatures = features.replace(\"National\",2)\nfeatures = features.replace(\"Sporting\",3)\nfeatures = features.replace(\"Cultural\",4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Data:\n    features = calender_data[{'wday','month','year','snap_CA','snap_TX','snap_WI'}]\n    \n    #features = calender_data[{'wday','month','year','snap_CA','snap_TX','snap_WI','event_type_1','event_type_2'}]\n    #features = features[0:len(features)]\n    #features = features.fillna(value=0)\n    #features = features.replace(\"Religious\",1)\n    #features = features.replace(\"National\",2)\n    #features = features.replace(\"Sporting\",3)\n    #features = features.replace(\"Cultural\",4)\n    \n    def __init__(self, item, store, dept, t1, t2):\n        self.item = item\n        self.store = store\n        self.dept = dept\n        self.t1 = t1\n        self.t2 = t2\n    \n    \n    # Custom data extraction function meant for looking at single series\n    def gen_data(self):\n        t1=self.t1; t2=self.t2\n        dept_sum = sales_data.groupby(['dept_id']).sum().T.reset_index(drop = True)\n        date_col = [col for col in sales_data if col.startswith('d_')]\n        sales_sum = pd.DataFrame(sales_data[date_col].sum(axis =0),columns = [\"sales\"]);\n        item = self.item\n        store = self.store\n        dept = self.dept    \n        \n        if dept == True:\n            data_store_foods = sales_data.groupby(['dept_id','store_id']).sum().T.reset_index(drop = True)\n            exp_data_total = data_store_foods[item,store]\n\n        if dept == False:\n            data_store_foods = sales_data.groupby(['item_id','store_id']).sum().T.reset_index(drop = True)\n            exp_data_total = data_store_foods[item,store]\n            \n        exp_data_train = exp_data_total[0:t1]\n\n        self.total = data_store_foods[item,store]\n        self.train = exp_data_train.values\n        if t2 < len(exp_data_total):\n            self.val = exp_data_total[t1:t2]\n        else:\n            self.val = \"ERROR: Test set required exceeds data available.\"\n        return 0\n    \n    def preprocess(self, data):\n        return denoise_signal(data)\n    \n    def post_process(self,y, lmbda):    \n        return inv_boxcox(y,lmbda) # = y,fitted_lambda \n    \n    def forecast_ARIMA(self, data):\n        t1=len(data); t2=len(data)+self.t2-self.t1\n        model = SARIMAX(data,order=(7,2,7),enforce_stationarity=False)\n        model_fit = model.fit(full_output=0,disp=0)\n\n        x = np.linspace(5,len(data),len(data))\n        \n        self.ARIMA_predict_train = model_fit.predict(0,len(data),typ='levels')\n        self.ARIMA_predict_forecast = model_fit.predict(t1,t2-1,typ='levels')\n        return 0\n    \n        \n    def forecast_NEGBIN(self, datal):\n        t1=self.t1; t2=self.t2\n        data = datal\n        exog = self.features\n        model = NegativeBinomialP(data, exog[t1-len(data):t1])\n        model_fit = model.fit(method='nm',full_output=0,disp=0)\n\n        self.NEGBIN_predict_train = model_fit.predict(exog)\n        self.NEGBIN_predict_forecast = model_fit.predict(exog[t1:t2])\n        return 0\n    \n    def forecast_MARKOV(self, datal):\n        t1=self.t1; t2=self.t2\n        data = datal\n        exog = self.features\n        k_regimes=3\n        model = MarkovRegression(data,k_regimes,trend=\"ct\")\n        model_fit = model.fit(method='nm',full_output=0,disp=0)\n        x = np.linspace(0,len(data),len(data))\n        self.VECTOR_predict_forecast = model_fit.predict(100-56)\n        return 0\n    \n    def forecast_SES(self, datal):\n        t1=self.t1; t2=self.t2\n        data = datal\n        exog = self.features\n        k_regimes=3\n        model = ExponentialSmoothing(data)\n        model_fit = model.fit()\n        x = np.linspace(0,len(data),len(data))\n        self.SES_predict_forecast = model_fit.predict(100-56)\n        return 0\n    \n    def forecast_POISSON(self, datal):\n        t1=self.t1; t2=self.t2\n        data = datal[0:len(datal)]\n        exog = self.features\n        model = Poisson(data, exog[t1-len(datal):t1])\n        model_fit = model.fit(full_output=0,disp=0)\n\n        self.POISSON_predict_train = model_fit.predict(exog)\n        self.POISSON_predict_forecast = model_fit.predict(exog[t1:t2])\n\n        \n        return 0\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Forecasting stuff**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_submission():\n    store_data = sales_data[\"store_id\"]\n    item_data = sales_data[\"item_id\"]\n    anal_end = len(sales_data)\n    val_days = 56\n    submission_out = np.zeros((anal_end,56))\n    submission_val = np.zeros((anal_end,28))\n    submission_eva = np.zeros((anal_end,28))\n\n    start_time = time.time()\n\n    train_data = sales_data.drop(columns=['id','cat_id','item_id','dept_id','store_id','state_id']).values\n    eri = 0\n    erih = 0\n    for i in range(anal_end):\n        dat = train_data[i]\n        dat0 = Data(item_data[i], store_data[i], False, 1913, 1969) # create data object for every series, extrapolate from 1913 to 1969\n        preproc = dat\n        try:\n            dat0.forecast_POISSON(preproc[-101:-1]); # Run the method to train and forecast the single series\n            foreout = dat0.POISSON_predict_forecast\n            \n            comp = mean(map(float, preproc[-21:-1]))+4*stdev(map(float,preproc[-21:-1]))\n            if np.any(foreout > comp) == True:\n                foreout = mean(preproc[-1969-1913:-1])\n                erih = erih+1\n        except: # for when the method fails to converge\n            foreout = mean(preproc[-1969-1913:-1])\n            eri = eri+1\n        \n        if np.isnan(np.min(foreout)) == True: # check for numbers\n            foreout = mean(preproc[-1969-1913:-1])\n            \n        submission_out[i] = np.round(foreout,3)\n        \n\n    submission_out[submission_out<0]=0\n    \n    print(\"Execution time: \",time.time()-start_time)\n    \n    # split submission into a validation (public scoreboard) and evaluation (private scoreboard) sets\n    submission_val = submission_out[:,0:28]\n    submission_eva = submission_out[:,28:56]\n\n    ids_tot = submission_data['id'].values\n    ids_val = pd.DataFrame(data=ids_tot[0:30489], columns=['id'])\n    ids_eva = pd.DataFrame(data=ids_tot[30490:], columns=['id'])\n\n    submission_val = pd.DataFrame(data=submission_val, columns=[f'F{i+1}' for i in range(28)])\n    submission_val = pd.concat([ids_val,submission_val],axis=1)\n\n    submission_eva = pd.DataFrame(data=submission_eva, columns=[f'F{i+1}' for i in range(28)])\n    submission_eva = pd.concat([ids_eva,submission_eva],axis=1)\n\n    submission = pd.concat([submission_val,submission_eva]).reset_index(drop=True)\n    submission['id'] = submission_data['id']\n    print(\"Number of crashes: \", eri)\n    print(\"Number of values exceeding mu+4*sigma: \", erih)\n    submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_submission()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}