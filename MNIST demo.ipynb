{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Deep learning with MNIST\n",
    "\n",
    "## Libraries\n",
    "\n",
    "As a first step we need to import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use tensorflow's version of Keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a dataset\n",
    "For this demo we use the MNIST dataset, which comes included with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Shape of the data\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test  = x_test.reshape(x_test.shape[0],   img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# Normalize images\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "num_classes = 10\n",
    "y_train_mat = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_mat = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some images from the dataset \n",
    "plt.figure(None,(18,18))\n",
    "for i in range(10):\n",
    "  plt.subplot(1,10,i+1)\n",
    "  plt.imshow(x_train[i].reshape(28,28),\"Greys\") # Show x_train[i]\n",
    "plt.show()\n",
    "# The corresponding labels\n",
    "print(\"Labels:\",y_train[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and training a model\n",
    "Now let's build a model, and train this using the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train 10 epochs with batches of 128 samples\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(x_train, y_train_mat,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test_mat))\n",
    "\n",
    "# How well does this model perform on the test set?\n",
    "score = model.evaluate(x_test, y_test_mat, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of accuracy during training\n",
    "plt.plot(history.epoch,history.history['accuracy'],label=\"Training accuracy\")\n",
    "plt.plot(history.epoch,history.history['val_accuracy'],label=\"Validation accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.epoch,history.history['loss'],label=\"Training loss\")\n",
    "plt.plot(history.epoch,history.history['val_loss'],label=\"Validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to a file is easy\n",
    "model.save('my-trained-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load a model, you don't need to specify the architecture\n",
    "model2 = keras.models.load_model('my-trained-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded model can be used for prediction and evaluation\n",
    "score = model2.evaluate(x_test, y_test_mat, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's train again, but training on the CPU\n",
    "# Only 1 epoch\n",
    "with tf.device('/CPU:0'):\n",
    "  history = model.fit(x_train, y_train_mat,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=1,\n",
    "                      verbose=1,\n",
    "                      validation_data=(x_test, y_test_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "Here are some questions for you\n",
    "\n",
    "1. The MNIST dataset consists of 60000 images for the trainingset, and 10000 for the testset. Looking at the accuracy, how many images from the testset are classified incorrectly?\n",
    "\n",
    "1. If we change the model by adding or removing layers, how does this affect the accuracy?\n",
    "\n",
    "1. Looking at the training loss, is there any point in continuing to train?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorrect classification\n",
    "Let's have a look at the inputs that are hard to classify for the network. Maybe this gives us some ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to predict the labels of the test set\n",
    "predicted_test = model.predict(x_test, batch_size=batch_size)\n",
    "\n",
    "# Convert scores into the index of the most likely class\n",
    "best_predicted_test = np.argmax(predicted_test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indices where the model is wrong \n",
    "wrong = np.argwhere(best_predicted_test != y_test)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the mistakes made by the network\n",
    "plt.figure(None,(18,18))\n",
    "for i in range(10):\n",
    "  plt.subplot(1,10,i+1)\n",
    "  plt.imshow(x_test[wrong[i]].reshape(28,28),\"Greys\")\n",
    "plt.show()\n",
    "print(\"Real labels     \", y_test[wrong[0:10]])\n",
    "print(\"Predicted labels\", best_predicted_test[wrong[0:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
